{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Arvid\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arvid\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arvid\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arvid\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Arvid\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arvid\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Arvid\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Arvid\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.1.0-cp310-cp310-win_amd64.whl (192.3 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.8.0)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\arvid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.3 filelock-3.12.4 fsspec-2023.9.2 jinja2-3.1.2 networkx-3.1 torch-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4\n",
    "%pip install matplotlib\n",
    "%pip install tqdm\n",
    "%pip install torch\n",
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19ad458a550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return dot(vec1, vec2)/(norm(vec1)*norm(vec2))\n",
    "\n",
    "def closest2(target_word, embeddings, count = 10):\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for word in embeddings:\n",
    "        scores.append((word, cosine_similarity(embeddings[word], embeddings[target_word])))\n",
    "    \n",
    "    result = []\n",
    "    scores.sort(key = lambda x: x[1], reverse = True)\n",
    "    for i in range(count):\n",
    "        result.append(scores[i][0])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in sentence:\n",
    "            if tolower:\n",
    "                x.append(row[key_x].lower())\n",
    "            else :\n",
    "                x.append(row[key_x])\n",
    "            y.append(row[key_y])\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = []\n",
    "chunks = []\n",
    "for sentence in train_sentences:\n",
    "    for line in sentence.split('\\n'):\n",
    "        (word, pos, chunk) = line.split()\n",
    "        word = word.lower()\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "        if chunk not in chunks:\n",
    "            chunks.append(chunk)\n",
    "words.sort()\n",
    "chunks.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = list(set(words + embedded_words))\n",
    "vocabulary_words.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {0: '<pad>', 1: '<unk>'}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    idx2word[i+2] = word\n",
    "    \n",
    "idx2chunk = {i+1: chunk for i, chunk in enumerate(chunks)}\n",
    "\n",
    "word2idx = {}\n",
    "for i, word in idx2word.items():\n",
    "    word2idx[word] = i\n",
    "\n",
    "chunk2idx = {chunk: i for i, chunk in idx2chunk.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<pad>', 0), ('<unk>', 1), ('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] if word in word2idx else word2idx['<unk>'] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True, padding_value=word2idx['<pad>'])\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=bidi_lstm)\n",
    "        self.fc = nn.Linear(lstm_units * 2 if bidi_lstm else lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeddings = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)\n",
    "# Assuming `model` is your model and `data` is your data.\n",
    "#print(torch.cuda.is_available())\n",
    "#model1 = model1.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:09<00:00, 29.54it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.52it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.35it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.53it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.40it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.38it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.43it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.18it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.41it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.51it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.49it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.30it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.77it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.71it/s]\n",
      "100%|██████████| 280/280 [00:09<00:00, 29.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [idx for idx in [word2idx[word] if word in word2idx else word2idx['<unk>'] for word in sentence]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "model1.eval()\n",
    "sent_chunk_predictions = model1(torch.tensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.8078e-09, 1.0814e-06, 2.6033e-06, 1.7776e-08, 3.0417e-07, 7.8263e-07,\n",
       "        9.9993e-01, 8.6851e-07, 1.4109e-08, 1.5594e-07, 1.2399e-08, 2.7258e-09,\n",
       "        4.7306e-09, 2.0264e-09, 1.0953e-08, 5.9730e-09, 2.2319e-06, 2.8827e-09,\n",
       "        2.4490e-08, 2.1923e-09, 3.8808e-08, 1.0181e-10, 6.0442e-05],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "<unk>: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx[word] if word in word2idx else word2idx['<unk>'] for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-3.9883,  0.8938, -2.0619,  ..., -1.3018, -3.6304,  2.7291],\n",
      "        [-5.3257, -3.3617, -1.1158,  ..., -3.1661, -0.5423,  5.7365],\n",
      "        [-5.6922, -0.3594, -0.8608,  ..., -3.8001, -5.1582,  3.1975],\n",
      "        ...,\n",
      "        [-2.2688,  1.5858, -0.4684,  ..., -0.5390, -2.0692,  6.6804],\n",
      "        [-2.1167,  1.6069, -0.4104,  ..., -0.4469, -2.0436,  6.3462],\n",
      "        [-1.9721,  1.6047, -0.3470,  ..., -0.3508, -2.1087,  6.1316]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022778900860722"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
